{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "992b69b1",
   "metadata": {},
   "source": [
    "## Early Classification, with pretrained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7b579d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as Func\n",
    "\n",
    "from pytorch_sklearn import NeuralNetwork\n",
    "from pytorch_sklearn.callbacks import WeightCheckpoint, Verbose, LossPlot, EarlyStopping, Callback, CallbackInfo\n",
    "from pytorch_sklearn.utils.func_utils import to_safe_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15bc0233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from ecg_utilities.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from ecg_utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a58b832",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_ids = pd.read_csv(osj(\"..\", \"files\", \"patient_ids.csv\"), header=None).to_numpy().reshape(-1)\n",
    "valid_patients = pd.read_csv(osj(\"..\", \"files\", \"valid_patients.csv\"), header=None).to_numpy().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2930c32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = osj(\"..\", \"dataset_training\", \"dataset_domain_adapted\")\n",
    "TRIO_PATH = osj(\"..\", \"dataset_training\", \"dataset_beat_trios_domain_adapted\")\n",
    "DICT_PATH = osj(\"..\", \"dictionaries\", \"dictionaries_5min_sorted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6703bb32",
   "metadata": {},
   "source": [
    "### Efficiency vs F1 with DA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d69c77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_PATH = osj(\"..\", \"pretrained\", \"nets\")\n",
    "SAVE_PATH = osj(\"..\", \"savefolder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a39e9eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = [-1]\n",
    "batch_sizes = [1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3df44d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [====================] - 233\u001b[2k\u001b[2k\n",
      "34/34 [====================] - 233\u001b[2k\n",
      "34/34 [====================] - 233\u001b[2k\n",
      "34/34 [====================] - 233\u001b[2k\n",
      "34/34 [====================] - 233\u001b[2k\n",
      "34/34 [====================] - 233\u001b[2k\n",
      "34/34 [====================] - 233\u001b[2k\n",
      "34/34 [====================] - 233\u001b[2k\n",
      "34/34 [====================] - 233\u001b[2k\n",
      "34/34 [====================] - 233\u001b[2k\u001b[2k\n",
      "Wall time: 48.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_patient_cms = []\n",
    "all_cms = []\n",
    "repeats = 10\n",
    "\n",
    "for repeat in range(repeats):\n",
    "    patient_cms = {percentile:{} for percentile in range(0, 101)}\n",
    "    cm = {percentile:torch.zeros(2, 2) for percentile in range(0, 101)}\n",
    "    \n",
    "    for i, patient_id in enumerate(valid_patients):\n",
    "        dataset = load_N_channel_dataset(patient_id, DATASET_PATH, TRIO_PATH)\n",
    "        train_X, train_y, train_ids, val_X, val_y, val_ids, test_X, test_y, test_ids = dataset.values()\n",
    "        \n",
    "        # For consulting through error energy.\n",
    "        D, F = load_dictionary(patient_id, DICT_PATH)\n",
    "        D, F = torch.Tensor(D), torch.Tensor(F)\n",
    "        \n",
    "        E = get_error_one_patient(test_X[:, 0, :].squeeze(), F, as_energy=True)\n",
    "        \n",
    "        # Load the neural network.\n",
    "        model = get_base_model(in_channels=train_X.shape[1])\n",
    "        model = model.to(\"cuda\")\n",
    "        crit = nn.CrossEntropyLoss()\n",
    "        optim = torch.optim.AdamW(params=model.parameters())\n",
    "        \n",
    "        net = NeuralNetwork.load_class(osj(LOAD_PATH, f\"net_{repeat+1}_{patient_id}\"), model, optim, crit)\n",
    "        weight_checkpoint_val_loss = net.cbmanager.callbacks[1]  # <- this needs to change in case weight checkpoint is not the second callback.\n",
    "        \n",
    "        net.load_weights(weight_checkpoint_val_loss)\n",
    "        pred_y = net.predict(test_X, batch_size=1024, use_cuda=True, fits_gpu=True, decision_func=lambda pred_y: pred_y.argmax(dim=1)).cpu()\n",
    "        \n",
    "        for percentile in range(0, 101):\n",
    "            thresh = np.percentile(E, percentile)\n",
    "            less_than = E < thresh\n",
    "            greater_than = E >= thresh\n",
    "\n",
    "            final_pred_y = torch.Tensor(np.select([less_than, greater_than], [torch.zeros_like(pred_y), pred_y])).long()\n",
    "            cm_exp = get_confusion_matrix(final_pred_y, test_y, pos_is_zero=False)\n",
    "\n",
    "            patient_cms[percentile][patient_id] = cm_exp\n",
    "            cm[percentile] += cm_exp\n",
    "            \n",
    "        print_progress(i + 1, len(valid_patients), opt=[f\"{patient_id}\"])\n",
    "        \n",
    "    all_patient_cms.append(patient_cms)\n",
    "    all_cms.append(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d270609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    learning_rate=0.001,\n",
    "    max_epochs=max_epochs[0],\n",
    "    batch_size=batch_sizes[0],\n",
    "    optimizer=optim.__class__.__name__,\n",
    "    loss=crit.__class__.__name__,\n",
    "    early_stopping=\"true\",\n",
    "    checkpoint_on=weight_checkpoint_val_loss.tracked,\n",
    "    dataset=\"default+trio\",\n",
    "    info=\"2-channel run, domain adapted, early classification performance based on efficiency.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "209964f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    with open(osj(SAVE_PATH, \"cms.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(all_cms, f)\n",
    "        \n",
    "    with open(osj(SAVE_PATH, \"config.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(config, f)\n",
    "        \n",
    "    with open(osj(SAVE_PATH, \"patient_cms.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(all_patient_cms, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd47eab9",
   "metadata": {},
   "source": [
    "### Efficiency vs F1 with DA and Ensemble Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddf984de",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_PATH = osj(\"..\", \"pretrained\", \"nets\")\n",
    "SAVE_PATH = osj(\"..\", \"savefolder\")\n",
    "CONF_PATH = osj(\"..\", \"pretrained\", \"confidences.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06390edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = [-1]\n",
    "batch_sizes = [1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10adc3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CONF_PATH, \"rb\") as f:\n",
    "    confs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bede03af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [====================] - 233\u001b[2k\n",
      "34/34 [====================] - 233\u001b[2k\n",
      "34/34 [====================] - 233\u001b[2k\n",
      "34/34 [====================] - 233\u001b[2k\n",
      "34/34 [====================] - 233\u001b[2k\n",
      "34/34 [====================] - 233\u001b[2k\n",
      "34/34 [====================] - 233\u001b[2k\n",
      "34/34 [====================] - 233\u001b[2k\n",
      "34/34 [====================] - 233\u001b[2k\n",
      "34/34 [====================] - 233\u001b[2k\n",
      "Wall time: 48.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_patient_cms = []\n",
    "all_cms = []\n",
    "repeats = 10\n",
    "\n",
    "for repeat in range(repeats):\n",
    "    patient_cms = {percentile:{} for percentile in range(0, 101)}\n",
    "    cm = {percentile:torch.zeros(2, 2) for percentile in range(0, 101)}\n",
    "    \n",
    "    for i, patient_id in enumerate(valid_patients):\n",
    "        dataset = load_N_channel_dataset(patient_id, DATASET_PATH, TRIO_PATH)\n",
    "        train_X, train_y, train_ids, val_X, val_y, val_ids, test_X, test_y, test_ids = dataset.values()\n",
    "        \n",
    "        # For consulting through error energy.\n",
    "        D, F = load_dictionary(patient_id, DICT_PATH)\n",
    "        D, F = torch.Tensor(D), torch.Tensor(F)\n",
    "        \n",
    "        ## Consulting Exponential - Gaussian.\n",
    "        BF = BayesianFit()\n",
    "        EF = ExponentialFit()\n",
    "        GF = GaussianFit()\n",
    "\n",
    "        # Train error.\n",
    "        train_E, E_healthy, E_arrhyth = get_error_one_patient(train_X[:, 0, :].squeeze(), F, y=train_y, as_energy=True)\n",
    "        \n",
    "        # Test Error\n",
    "        test_E = get_error_one_patient(test_X[:, 0, :].squeeze(), F, as_energy=True)\n",
    "        \n",
    "        EF.fit(E_healthy)\n",
    "        GF.fit(E_arrhyth)\n",
    "        consult_test_y = torch.Tensor(BF.predict(test_E, EF, GF) <= 0.5).long()\n",
    "        ##\n",
    "        \n",
    "        # Load the neural network.\n",
    "        model = get_base_model(in_channels=train_X.shape[1])\n",
    "        model = model.to(\"cuda\")\n",
    "        crit = nn.CrossEntropyLoss()\n",
    "        optim = torch.optim.AdamW(params=model.parameters())\n",
    "        \n",
    "        net = NeuralNetwork.load_class(osj(LOAD_PATH, f\"net_{repeat+1}_{patient_id}\"), model, optim, crit)\n",
    "        weight_checkpoint_val_loss = net.cbmanager.callbacks[1]  # <- this needs to change in case weight checkpoint is not the second callback.\n",
    "        \n",
    "        net.load_weights(weight_checkpoint_val_loss)\n",
    "        \n",
    "        # Test predictions and probabilities.\n",
    "        pred_y = net.predict(test_X, batch_size=1024, use_cuda=True, fits_gpu=True, decision_func=lambda pred_y: pred_y.argmax(dim=1)).cpu()\n",
    "        prob_y = net.predict_proba(test_X).cpu()\n",
    "        softmax_prob_y = Func.softmax(prob_y, dim=1).max(dim=1).values\n",
    "        \n",
    "        for percentile in range(0, 101):\n",
    "            thresh = np.percentile(test_E, percentile)\n",
    "            less_than = test_E < thresh\n",
    "            greater_than = test_E >= thresh\n",
    "            \n",
    "            conf = confs[repeat][i]\n",
    "            low_confidence = softmax_prob_y < conf\n",
    "            high_confidence = softmax_prob_y >= conf\n",
    "\n",
    "            # These are neural network vs probabilistic model predictions based on confidence.\n",
    "            final_pred_y = torch.Tensor(np.select([low_confidence, high_confidence], [consult_test_y, pred_y])).long()\n",
    "            \n",
    "            # Signals below threshold are early classified, the rest are classified with confidence.\n",
    "            final_pred_y = torch.Tensor(np.select([less_than, greater_than], [torch.zeros_like(final_pred_y), final_pred_y])).long()\n",
    "            cm_exp = get_confusion_matrix(final_pred_y, test_y, pos_is_zero=False)\n",
    "\n",
    "            patient_cms[percentile][patient_id] = cm_exp\n",
    "            cm[percentile] += cm_exp\n",
    "            \n",
    "        print_progress(i + 1, len(valid_patients), opt=[f\"{patient_id}\"])\n",
    "        \n",
    "    all_patient_cms.append(patient_cms)\n",
    "    all_cms.append(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85f6e14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    learning_rate=0.001,\n",
    "    max_epochs=max_epochs[0],\n",
    "    batch_size=batch_sizes[0],\n",
    "    optimizer=optim.__class__.__name__,\n",
    "    loss=crit.__class__.__name__,\n",
    "    early_stopping=\"true\",\n",
    "    checkpoint_on=weight_checkpoint_val_loss.tracked,\n",
    "    dataset=\"default+trio\",\n",
    "    info=\"2-channel run, domain adapted, consulted, early classification performance based on efficiency.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d870e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    with open(osj(SAVE_PATH, \"cms.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(all_cms, f)\n",
    "        \n",
    "    with open(osj(SAVE_PATH, \"config.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(config, f)\n",
    "        \n",
    "    with open(osj(SAVE_PATH, \"patient_cms.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(all_patient_cms, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
