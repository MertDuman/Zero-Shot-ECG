{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95ad6666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "from scipy import linalg as spl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from os.path import join as osj\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "from progress_bar import print_progress\n",
    "\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5243a599",
   "metadata": {},
   "source": [
    "## Everything related to loading ECG datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2220069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict_beats(PATH):\n",
    "    with open(PATH, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def load_data_beats(PATH):\n",
    "    with open(PATH, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def ensure_normalized_and_detrended(beats):\n",
    "    for key in beats.keys():\n",
    "        b = beats[key][\"beats\"]\n",
    "        if not np.allclose(np.linalg.norm(b, axis=1, ord=2), 1):\n",
    "            raise AssertionError(f\"Beats of patient {key} is not normalized.\")\n",
    "            \n",
    "        p = np.polyfit(np.arange(b.shape[1]), b.T, deg=1)\n",
    "        if not np.allclose(p, 0):\n",
    "            raise AssertionError(f\"Beats of patient {key} is not detrended.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d26b598f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(patient_id, PATH):\n",
    "    \"\"\" \n",
    "    Reads the pickled ECG dataset from the given path for the given patient.\n",
    "    The file name must be \"patient_<patient_id>_dataset.pkl\".\n",
    "    \"\"\"\n",
    "    with open(osj(PATH, f\"patient_{patient_id}_dataset.pkl\"), \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def load_dictionary(patient_id, PATH):\n",
    "    \"\"\"\n",
    "    Reads the pickled ECG dictionary from the given path for the given patient.\n",
    "    The file name must be \"patient_<patient_id>_dictionary.pkl\".\n",
    "    \"\"\"\n",
    "    with open(osj(PATH, f\"patient_{patient_id}_dictionary.pkl\"), \"rb\") as f:\n",
    "        D = pickle.load(f)\n",
    "        F = spl.null_space(D.T)\n",
    "        F = spl.orth(F).T\n",
    "    return D, F\n",
    "\n",
    "def dataset_to_tensors(dataset):\n",
    "    \"\"\"\n",
    "    Converts the given dataset to torch tensors in appropriate data types and shapes.\n",
    "    \"\"\"\n",
    "    dataset = dataset.copy()\n",
    "    train_X, train_y, train_ids, val_X, val_y, val_ids, test_X, test_y, test_ids = dataset.values()\n",
    "    dataset[\"train_X\"] = torch.Tensor(train_X).float().reshape(-1, 1, train_X.shape[1])\n",
    "    dataset[\"train_y\"] = torch.Tensor(train_y).long()\n",
    "    dataset[\"train_ids\"] = torch.Tensor(train_ids).long()\n",
    "    dataset[\"val_X\"] = torch.Tensor(val_X).float().reshape(-1, 1, val_X.shape[1])\n",
    "    dataset[\"val_y\"] = torch.Tensor(val_y).long()\n",
    "    dataset[\"val_ids\"] = torch.Tensor(val_ids).long()\n",
    "    dataset[\"test_X\"] = torch.Tensor(test_X).float().reshape(-1, 1, test_X.shape[1])\n",
    "    dataset[\"test_y\"] = torch.Tensor(test_y).long()\n",
    "    dataset[\"test_ids\"] = torch.Tensor(test_ids).long()\n",
    "    return dataset\n",
    "\n",
    "def add_dataset(patient_id, dataset, DATASET_PATH):\n",
    "    \"\"\"\n",
    "    Adds another dataset to an already existing one, increasing the number of channels.\n",
    "    \"\"\"\n",
    "    dataset = dataset.copy()\n",
    "    dataset_other = load_dataset(patient_id, DATASET_PATH)\n",
    "    dataset_other = dataset_to_tensors(dataset_other)\n",
    "    \n",
    "    assert torch.equal(dataset[\"train_y\"], dataset_other[\"train_y\"]), \"Training ground truths are different. Possibly shuffled differently.\"\n",
    "    assert torch.equal(dataset[\"val_y\"], dataset_other[\"val_y\"]), \"Validation ground truths are different. Possibly shuffled differently.\"\n",
    "    assert torch.equal(dataset[\"test_y\"], dataset_other[\"test_y\"]), \"Test ground truths are different. Possibly shuffled differently.\"\n",
    "    \n",
    "    train_X, train_y, train_ids, val_X, val_y, val_ids, test_X, test_y, test_ids = dataset.values()\n",
    "    train_other_X, _, _, val_other_X, _, _, test_other_X, _, _ = dataset_other.values()\n",
    "    dataset[\"train_X\"] = torch.cat((train_X, train_other_X), dim=1)\n",
    "    dataset[\"val_X\"] = torch.cat((val_X, val_other_X), dim=1)\n",
    "    dataset[\"test_X\"] = torch.cat((test_X, test_other_X), dim=1)\n",
    "    return dataset\n",
    "\n",
    "def load_N_channel_dataset(patient_id, DEFAULT_PATH, *PATHS):\n",
    "    \"\"\"\n",
    "    Loads the ECG dataset at the given path(s) for the given patient. Each dataset will be added as a new\n",
    "    channel in the given order.\n",
    "    \"\"\"\n",
    "    default_dataset = load_dataset(patient_id, DEFAULT_PATH)\n",
    "    default_dataset = dataset_to_tensors(default_dataset)\n",
    "    for PATH in PATHS:\n",
    "        default_dataset = add_dataset(patient_id, default_dataset, PATH)\n",
    "    return default_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391fdbe7",
   "metadata": {},
   "source": [
    "## Dictionary errors from the annihilator matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2ab2bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_one_patient(S, F, y=None, as_energy=False):\n",
    "    \"\"\"\n",
    "    Returns the error, E = S @ F.T\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    S : array_like\n",
    "        ECG signals of shape (N x K), where K is signal length.\n",
    "    F : array_like\n",
    "        Dictionary null-space of shape (M x K), where M is error signal length.\n",
    "    y : array_like\n",
    "        Array of labels of shape (N). If provided, errors are returned separately for healthy and arrhythmia.\n",
    "    as_energy : bool\n",
    "        If True, error energies are returned instead.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert F.shape[1] == S.shape[1], f\"F and S can't be matrix multiplied. Provide S as a matrix with shape (N x {F.shape[1]}).\"\n",
    "    assert y is None or len(np.unique(y)) == 2, f\"There must be 2 classes. Found {len(np.unique(y))} classes.\"\n",
    "    \n",
    "    E = S @ F.T\n",
    "    \n",
    "    if as_energy:\n",
    "        E = E.pow(2).sum(dim=1)\n",
    "    \n",
    "    if y is not None:\n",
    "        healthy = np.where(y == 0)[0]\n",
    "        arrhyth = np.where(y == 1)[0]\n",
    "\n",
    "        E_healthy = E[healthy]\n",
    "        E_arrhyth = E[arrhyth]\n",
    "        \n",
    "        return E, E_healthy, E_arrhyth\n",
    "    return E\n",
    "\n",
    "def get_error_per_patient(S, ids, DICT_PATH, y=None, as_energy=False):\n",
    "    \"\"\"\n",
    "    Returns the error, E = S_i @ F_i.T, where S_i and F_i are the signals and null-space of patient i.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    S : array_like\n",
    "        ECG signals of shape (N x K), where K is signal length.\n",
    "    ids : array_like\n",
    "        ids[i] is the id of the patient that S[i] belongs to.\n",
    "    DICT_PATH : str\n",
    "        Path to the folder that has the dictionary of the users.\n",
    "    y : array_like\n",
    "        Array of labels of shape (N). If provided, errors are returned separately for healthy and arrhythmia.\n",
    "    as_energy : bool\n",
    "        If True, error energies are returned instead.\n",
    "    \"\"\"\n",
    "    \n",
    "    _, F = load_dictionary(ids[0], DICT_PATH)\n",
    "    F = torch.Tensor(F).float()\n",
    "    E_shape = S.shape[0] if as_energy else [S.shape[0], F.shape[0]]\n",
    "    Es = torch.empty(E_shape)\n",
    "    \n",
    "    for id_ in ids.unique():\n",
    "        _, F = load_dictionary(id_, DICT_PATH)\n",
    "        F = torch.Tensor(F).float()\n",
    "        idx = np.where(ids == id_)[0]\n",
    "        E = get_error_one_patient(S[ids == id_], F, as_energy=as_energy)\n",
    "        Es[idx] = E\n",
    "    \n",
    "    if y is not None:\n",
    "        healthy = np.where(y == 0)[0]\n",
    "        arrhyth = np.where(y == 1)[0]\n",
    "\n",
    "        E_healthy = Es[healthy]\n",
    "        E_arrhyth = Es[arrhyth]\n",
    "        \n",
    "        return Es, E_healthy, E_arrhyth\n",
    "    \n",
    "    return Es"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206ebf40",
   "metadata": {},
   "source": [
    "## Model used to get the results in our paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ce1f370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_model(in_channels):\n",
    "    \"\"\"\n",
    "    Returns the model from paper: Personalized Monitoring and Advance Warning System for Cardiac Arrhythmias.\n",
    "    \"\"\"\n",
    "    # Input size: 128x1\n",
    "    # 128x1 -> 122x32 -> 40x32 -> 34x16 -> 11x16 -> 5x16 -> 1x16\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv1d(in_channels, 32, kernel_size=7, padding=0, bias=True),\n",
    "        nn.MaxPool1d(3),\n",
    "        nn.Tanh(),\n",
    "        \n",
    "        nn.Conv1d(32, 16, kernel_size=7, padding=0, bias=True),\n",
    "        nn.MaxPool1d(3),\n",
    "        nn.Tanh(),\n",
    "        \n",
    "        nn.Conv1d(16, 16, kernel_size=7, padding=0, bias=True),\n",
    "        nn.MaxPool1d(3),\n",
    "        nn.Tanh(),\n",
    "        \n",
    "        nn.Flatten(),\n",
    "        \n",
    "        nn.Linear(16, 32, bias=True),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Linear(32, 2, bias=True),\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52cdea8",
   "metadata": {},
   "source": [
    "## Probability classes and functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6960c92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExponentialFit:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X):\n",
    "        self.beta = X.mean()\n",
    "        self.fit_perf = np.sum(self.likelihood(X))\n",
    "    \n",
    "    def likelihood(self, X):\n",
    "        return sp.stats.expon(scale=self.beta).pdf(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fff6a70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianFit:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X):\n",
    "        self.mu = X.mean()\n",
    "        self.std = X.std()\n",
    "        self.fit_perf = np.sum(self.likelihood(X))\n",
    "    \n",
    "    def likelihood(self, X):\n",
    "        return sp.stats.norm(loc=self.mu, scale=self.std).pdf(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0319bb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KDEFit:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X):\n",
    "        self.kde = sp.stats.gaussian_kde(X, bw_method=0.05)\n",
    "        \n",
    "    def likelihood(self, X):\n",
    "        return self.kde.pdf(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ee87ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianFit:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def predict(self, X, model1, model2, prior1=1, prior2=1):\n",
    "        like1 = model1.likelihood(X) * prior1\n",
    "        like2 = model2.likelihood(X) * prior2\n",
    "        odd1 = like1 / like2\n",
    "        return odd1 / (1 + odd1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceddabc",
   "metadata": {},
   "source": [
    "## Performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a41f9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance_metrics(cm):\n",
    "    \"\"\"\n",
    "    Calculates:\n",
    "        accuracy\n",
    "        true positive rate (recall, sensitivity)\n",
    "        specificity (1 - false positive rate)\n",
    "        positive predictive value (PPV, precision)\n",
    "        negative predictive value (NPV)\n",
    "        F1-score\n",
    "    from the given confusion matrix.\n",
    "    \"\"\"\n",
    "    cm = np.asarray(cm).copy().astype(np.long)\n",
    "    tp, fp, tn, fn = cm[0,0], cm[0,1], cm[1,1], cm[1,0]\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    rec = tp / (tp + fn)\n",
    "    spe = tn / (tn + fp)\n",
    "    pre = tp / (tp + fp)\n",
    "    npv = tn / (tn + fn)\n",
    "    f1 = (2 * pre * rec) / (pre + rec)\n",
    "    metrics = {\"acc\":acc, \"rec\":rec, \"spe\":spe, \"pre\":pre, \"npv\":npv, \"f1\":f1}\n",
    "    return metrics\n",
    "\n",
    "def get_confusion_matrix(pred_y, true_y, pos_is_zero=False):\n",
    "    \"\"\"\n",
    "    Calculates the confusion matrix for the given predictions and truth values. \n",
    "    \n",
    "    Set pos_is_zero to True if the positive sample's class index is 0.\n",
    "    In the case of our ECG work, positive means an abnormal beat, and has a class index of 1.\n",
    "    \"\"\"\n",
    "    pred_y = torch.as_tensor(pred_y, dtype=torch.long)\n",
    "    true_y = torch.as_tensor(true_y, dtype=torch.long)\n",
    "    vals = true_y + 2 * pred_y   # 0,0 -> 0    1,0 -> 1    0,1 -> 2    1,1 -> 3\n",
    "    cm = torch.zeros(4).long()  \n",
    "    cm += torch.bincount(vals, minlength=4)\n",
    "    cm = cm.reshape(2, 2)\n",
    "    \n",
    "    if not pos_is_zero:\n",
    "        return cm.flip((0, 1))\n",
    "    return cm\n",
    "\n",
    "# @deprecated\n",
    "def get_confusion_matrix_deprecated(pred_y, true_y, pos_is_zero=False):\n",
    "    cm = torch.zeros(2, 2).long()\n",
    "    for py, ty in zip(pred_y, true_y):\n",
    "        if not pos_is_zero:\n",
    "            py = 1 - py\n",
    "            ty = 1 - ty\n",
    "        cm[py, ty] += 1\n",
    "    return cm\n",
    "\n",
    "# @deprecated\n",
    "def get_cm_generating_data_deprecated(cm):\n",
    "    \"\"\" \n",
    "    Previously needed for WandB. \n",
    "    Creates pseudo-data that would generate the given confusion matrix.\n",
    "    \"\"\"\n",
    "    cm = np.asarray(cm).copy().astype(np.long)\n",
    "    tp, fp, tn, fn = cm[0,0], cm[0,1], cm[1,1], cm[1,0]\n",
    "    pred_y = torch.cat((torch.ones(tp), torch.zeros(tn), torch.ones(fp), torch.zeros(fn))).long()\n",
    "    test_y = torch.cat((torch.ones(tp), torch.zeros(tn), torch.zeros(fp), torch.ones(fn))).long()\n",
    "    return pred_y, test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad725986",
   "metadata": {},
   "source": [
    "## Dictionary and Sparse Key generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af3a6b2",
   "metadata": {},
   "source": [
    "**Solves the Lasso problem:**\n",
    "$$ \\underset{\\vec{x}}{\\arg\\min} \\dfrac{1}{2}\\|\\mathbf{A}\\vec{x} - \\vec{b}\\|_2^2 + \\lambda\\|\\vec{x}\\|_1 $$\n",
    "\n",
    "**using [Alternating Direction Method of Multipliers](https://statweb.stanford.edu/~candes/teaching/math301/Lectures/Consensus.pdf). In our case, this corresponds to:**\n",
    "\n",
    "$$ \\underset{\\vec{h}}{\\arg\\min} \\|\\mathbf{D}\\vec{h} - \\vec{x}\\|_2^2 + \\lambda\\|\\vec{h}\\|_1 $$\n",
    "\n",
    "**where $\\mathbf{D}$ is the dictionary matrix, $\\vec{h}$ is the keys, and $\\vec{x}$ is the signal represented using $\\mathbf{D}\\vec{h}$. We can also represent an entire dataset of signals as $\\mathbf{D}\\mathbf{H} = \\mathbf{X}$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef593a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dictionary(S, num_atoms=20, delta_err=None, max_it=100, max_admm=100, calc_err=False, seed=0, printing=False):\n",
    "    \"\"\"\n",
    "    Generate a dictionary that represents the signals given in S ∈ (N x F) with sparse keys, minimizing the Lasso loss.\n",
    "    D ∈ (F x num_atoms).\n",
    "    X ∈ (num_atoms x N).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    S : array_like\n",
    "        Signals to be represented. S ∈ (N x F).\n",
    "    num_atoms : int\n",
    "        Number of dictionary elements.\n",
    "    delta_err : float, default=None\n",
    "        Stopping criteria for change in error. Stops if the decrease in error is less than (current error * delta_err): \n",
    "            Stops if: err(t-1) - err(t) < err(t-1) * delta_err\n",
    "        Note: calc_err must be true. If calc_err is False, max_it is used. If max_it is reached, we stop regardless.\n",
    "    \"\"\"\n",
    "    assert delta_err is None or calc_err, \"Early stopping is not possible without error calculations.\"  # delta_err implies calc_err\n",
    "        \n",
    "    np.random.seed(seed)\n",
    "    S = S.T  # S ∈ (F x N)\n",
    "    D = np.random.randn(S.shape[0], num_atoms)\n",
    "    D = D / np.linalg.norm(D, axis=0, ord=2)\n",
    "    k = 0\n",
    "    if calc_err:\n",
    "        E = np.zeros(max_it)\n",
    "    \n",
    "    while k < max_it:\n",
    "        X = lasso_solver_ADMM(D, S, max_it=max_admm)\n",
    "        D = S @ np.linalg.pinv(X)  # DX = S  ->  DXX+ = SX+  ->  D = SX+            (Y @ S') \\ (S @ S')\n",
    "        D = D / np.linalg.norm(D, axis=0, ord=2)\n",
    "        \n",
    "        if calc_err:\n",
    "            err = np.linalg.norm((D @ X) - S, ord=2, axis=None)\n",
    "            E[k] = err\n",
    "            if k > 1 and delta_err is not None and np.abs(E[k - 1] - E[k]) < E[k - 1] * delta_err:\n",
    "                if printing:\n",
    "                    print_progress(k + 1, max_it, add_newline=True)\n",
    "                    print(f\"Stopping early. Abs error diff: {np.abs(E[k - 1] - E[k]):.2e}, Threshold: {E[k - 1] * delta_err:.2e}\")\n",
    "                k = k + 1\n",
    "                return D, X, E[:k]\n",
    "            \n",
    "        k = k + 1\n",
    "        if printing:\n",
    "            print_progress(k, max_it)\n",
    "        \n",
    "    if calc_err:\n",
    "        return D, X, E\n",
    "    return D, X\n",
    "\n",
    "def lasso_solver_ADMM(A, b, max_it=100):\n",
    "    \"\"\"\n",
    "    Minimizes the lasso formulation |Ax - b|_2 + |x|_1 using ADMM.\n",
    "    \"\"\"\n",
    "    x = np.zeros((A.shape[1], b.shape[1]))\n",
    "    z = np.zeros_like(x)\n",
    "    y = np.zeros_like(x)\n",
    "    AtA = A.T @ A\n",
    "    I = np.eye(AtA.shape[0])\n",
    "    Atb = A.T @ b\n",
    "    tau_ = 0.08  # one over tau\n",
    "    lambda_tau = 0.01 / tau_  # lambda * tau\n",
    "    k = 0\n",
    "    \n",
    "    while k < max_it:\n",
    "        x = np.linalg.solve(AtA + tau_ * I, Atb + tau_ * (z - y))\n",
    "        z = soft_threshold(x + y, lambda_tau)\n",
    "        y = y + tau_ * (x - z)\n",
    "        k = k + 1\n",
    "        \n",
    "    return x\n",
    "\n",
    "def soft_threshold(x, lambda_):\n",
    "    \"\"\"\n",
    "    Implements:\n",
    "        x - lambda    if x > lambda\n",
    "        x + lambda    if x < -lambda\n",
    "        0             otherwise (x in [-lambda, lambda])\n",
    "    \"\"\"\n",
    "    return np.maximum(0, x - lambda_) - np.maximum(0, -lambda_ - x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52087aa",
   "metadata": {},
   "source": [
    "### Domain Adaptation from one patient to another. <br> Problem: Given two patients, modify the beats of one patient to improve its beat representation on another patient's dictionary.\n",
    "### $$ \n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\hat{Q}, \\hat{C}_j &= \\underset{Q,\\,C_j}{\\arg\\min} \\, J \\\\\n",
    "J &=  \\|QX_j - D_iC_j\\|_2^2 + \\|C_j\\|_1 + \\gamma\\|X_j - QX_j\\|_2^2 \\\\\n",
    "\\dfrac{\\partial J}{\\partial Q} &= 2\\left( QX_j - D_iC_j \\right)X_j^T - 2\\gamma\\left( X_j - Q_jX_j \\right)X_j^T \\\\\n",
    "  &= Q_jX_jX_j^T - D_iC_jX_j^T - \\gamma X_jX_j^T + \\gamma Q_jX_jX_j^T = 0 \\\\\n",
    "Q &= \\left( D_iC_jX_j^T + \\gamma X_jX_j^T \\right) \\left( X_jX_j^T + \\gamma X_jX_j^T \\right)^{-1}\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "$$ <br> where $Q$ is the matrix that transforms $X_j$ to another domain so that it is better represented with $D_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1718ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DomainAdapter():\n",
    "    def __init__(self):\n",
    "        self.adapted = False\n",
    "    \n",
    "    def adapt(self, Di, Sj, gamma: int, max_it: int=100, max_admm: int=100, plot=False):\n",
    "        Q = np.eye(Di.shape[0])\n",
    "        Sj = Sj.T\n",
    "        \n",
    "        # Save for speedup\n",
    "        SjSjT = Sj @ Sj.T\n",
    "        gSjSjT = gamma * SjSjT\n",
    "\n",
    "        if plot:\n",
    "            plt.figure()\n",
    "        for i in range(max_it):\n",
    "            QSj = Q @ Sj\n",
    "            if plot:\n",
    "                plt.plot(QSj[:, 0], label=f\"iter={i}\")\n",
    "            QSj = QSj / np.linalg.norm(QSj, axis=0, ord=2)\n",
    "            Cj = lasso_solver_ADMM(Di, QSj, max_it=max_admm)\n",
    "            Q = (Di @ Cj @ Sj.T + gSjSjT) @ np.linalg.pinv(SjSjT + gSjSjT)\n",
    "            \n",
    "        if plot:\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "        self.Q = Q\n",
    "        self.adapted = True\n",
    "        return Q\n",
    "    \n",
    "    def adapt_gd(self, Di, Sj, gamma: int, lr: float=0.01, max_epochs: int=100, max_admm: int=100, plot=False):\n",
    "        Q = np.eye(Di.shape[0])\n",
    "        Sj = Sj.T\n",
    "\n",
    "        # Save for speedup\n",
    "        SjSjT = Sj @ Sj.T\n",
    "        gSjSjT = gamma * SjSjT\n",
    "\n",
    "        if plot:\n",
    "            plt.figure()\n",
    "        for i in range(max_epochs):\n",
    "            QSj = Q @ Sj\n",
    "            if plot and i % 10 == 0:\n",
    "                plt.plot(QSj[:, 0], label=f\"iter={i}\")\n",
    "            QSj = QSj / np.linalg.norm(QSj, axis=0, ord=2)\n",
    "            Cj = lasso_solver_ADMM(Di, QSj, max_it=max_admm)\n",
    "            \n",
    "            grad_Q = Q @ SjSjT - Di @ Cj @ Sj.T - gSjSjT + gamma * Q @ SjSjT\n",
    "            Q = Q - lr * grad_Q\n",
    "        \n",
    "        if plot:\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        \n",
    "        self.Q = Q\n",
    "        self.adapted = True\n",
    "        return Q\n",
    "    \n",
    "    def test(self, Di, Si_D, Si_T, yi, Sj_D, Sj_T, yj, Q, max_it: int=100):\n",
    "        assert self.adapted, \"Call adapt first.\"\n",
    "        \n",
    "        # Fit of i's dictionary beats.\n",
    "        Ci_D = lasso_solver_ADMM(Di, Si_D.T, max_it=max_it)\n",
    "        Ei_D = np.linalg.norm((Di @ Ci_D) - Si_D.T, ord=2, axis=0).mean()\n",
    "        \n",
    "        # Fit of i's train/test beats.\n",
    "        Ci_T = lasso_solver_ADMM(Di, Si_T.T, max_it=max_it)\n",
    "        Ei_T = np.linalg.norm((Di @ Ci_T) - Si_T.T, ord=2, axis=0)\n",
    "        Ei_T_healthy = Ei_T[yi == \"N\"].mean()\n",
    "        Ei_T_arrhyth = Ei_T[yi != \"N\"].mean()\n",
    "        \n",
    "        # Fit of j's dictionary beats on i's dictionary.\n",
    "        Cj_D = lasso_solver_ADMM(Di, Sj_D.T, max_it=max_it)\n",
    "        Ej_D = np.linalg.norm((Di @ Cj_D) - Sj_D.T, ord=2, axis=0).mean()\n",
    "        \n",
    "        # Fit of j's train/test beats on i's dictionary.\n",
    "        Cj_T = lasso_solver_ADMM(Di, Sj_T.T, max_it=max_it)\n",
    "        Ej_T = np.linalg.norm((Di @ Cj_T) - Sj_T.T, ord=2, axis=0)\n",
    "        Ej_T_healthy = Ej_T[yj == \"N\"].mean()\n",
    "        Ej_T_arrhyth = Ej_T[yj != \"N\"].mean()\n",
    "        \n",
    "        # Fit of j's dictionary beats on i's dictionary after domain adaptation.\n",
    "        QSj_D = Q @ Sj_D.T\n",
    "        QSj_D = QSj_D / np.linalg.norm(QSj_D, axis=0, ord=2)\n",
    "        \n",
    "        DA_Cj_D = lasso_solver_ADMM(Di, QSj_D, max_it=max_it)\n",
    "        DA_Ej_D = np.linalg.norm((Di @ DA_Cj_D) - QSj_D, ord=2, axis=0).mean()\n",
    "        \n",
    "        # Fit of j's train/test beats on i's dictionary after domain adaptation.\n",
    "        QSj_T = Q @ Sj_T.T\n",
    "        QSj_T = QSj_T / np.linalg.norm(QSj_T, axis=0, ord=2)\n",
    "        \n",
    "        DA_Cj_T = lasso_solver_ADMM(Di, QSj_T, max_it=max_it)\n",
    "        DA_Ej_T = np.linalg.norm((Di @ DA_Cj_T) - QSj_T, ord=2, axis=0)\n",
    "        DA_Ej_T_healthy = DA_Ej_T[yj == \"N\"].mean()\n",
    "        DA_Ej_T_arrhyth = DA_Ej_T[yj != \"N\"].mean()\n",
    "        \n",
    "        d = {\n",
    "            \"Ei_D\": Ei_D, \"Ei_T_healthy\": Ei_T_healthy, \"Ei_T_arrhyth\": Ei_T_arrhyth,\n",
    "            \"Ej_D\": Ej_D, \"Ej_T_healthy\": Ej_T_healthy, \"Ej_T_arrhyth\": Ej_T_arrhyth,\n",
    "            \"DA_Ej_D\": DA_Ej_D, \"DA_Ej_T_healthy\": DA_Ej_T_healthy, \"DA_Ej_T_arrhyth\": DA_Ej_T_arrhyth\n",
    "        }\n",
    "        \n",
    "        return d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
