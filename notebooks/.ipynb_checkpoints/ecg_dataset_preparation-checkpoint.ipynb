{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baaae4c7",
   "metadata": {},
   "source": [
    "## Notebook for creating dictionaries, train, test, and validation sets for the proposed method, using the beats extracted from the MIT-BIH dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff65885e",
   "metadata": {},
   "source": [
    "### To-Do:\n",
    "**✅ Load the beats for each user.**\n",
    "\n",
    "**✅ Make sure each beat is detrended and normalized.**\n",
    "\n",
    "**✅ Create a dictionary for each patient from its 5 minute data.**\n",
    "\n",
    "**✅ Save the dictionaries.**\n",
    "\n",
    "**✅ Find the annihilator matrix of each dictionary.**\n",
    "\n",
    "**✅ For patient p, prepare p's dataset by getting other patients' healthy and arrhythmia beats. Healthy beats must be <= arrhythmia beats.**\n",
    "\n",
    "**✅ For patient p, also save the patient id's where each beat comes from, shuffle the datasets, and do train/validation splits.**\n",
    "\n",
    "**✅ Save the datasets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1fb7c989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy import io as sio\n",
    "from scipy import signal as sps\n",
    "from scipy import linalg as spl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from os.path import join as osj\n",
    "from bisect import bisect\n",
    "from collections import defaultdict \n",
    "import pickle\n",
    "import json\n",
    "\n",
    "from progress_bar import print_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4774ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dict_beats():\n",
    "    with open(DICT_BEATS, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def read_data_beats():\n",
    "    with open(DATA_BEATS, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def ensure_normalized_and_detrended(beats):\n",
    "    for key in beats.keys():\n",
    "        b = beats[key][\"beats\"]\n",
    "        if not np.allclose(np.linalg.norm(b, axis=1, ord=2), 1):\n",
    "            raise AssertionError(f\"Beats of patient {key} is not normalized.\")\n",
    "            \n",
    "        p = np.polyfit(np.arange(b.shape[1]), b.T, deg=1)\n",
    "        if not np.allclose(p, 0):\n",
    "            raise AssertionError(f\"Beats of patient {key} is not detrended.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3f7f09",
   "metadata": {},
   "source": [
    "**Solves the Lasso problem:**\n",
    "$$ \\underset{\\vec{x}}{\\arg\\min} \\left[\\dfrac{1}{2}\\|\\mathbf{A}\\vec{x} - \\vec{b}\\|_2^2 + \\lambda\\|\\vec{x}\\|_1 \\right] $$\n",
    "\n",
    "**using [Alternating Direction Method of Multipliers](https://statweb.stanford.edu/~candes/teaching/math301/Lectures/Consensus.pdf). In our case, this corresponds to:**\n",
    "$$ \\underset{\\mathbf{\\vec{x}}}{\\arg\\min} \\left[\\|\\mathbf{D\\vec{x} - \\vec{s}}\\|_2^2 + \\lambda\\|\\mathbf{\\vec{x}}\\|_1 \\right] $$\n",
    "\n",
    "**where $\\mathbf{D}$ is the dictionary matrix, $\\mathbf{\\vec{x}}$ is the keys, and $\\mathbf{\\vec{s}}$ is the signal represented using $\\mathbf{D}\\vec{x}$. We can also represent an entire dataset of signals as $\\mathbf{D}\\mathbf{X} = \\mathbf{S}$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c15074b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dictionary(S, num_atoms=20, delta_err=None, max_it=100, max_admm=100, calc_err=False, seed=0, printing=False):\n",
    "    \"\"\"\n",
    "    Generate a dictionary that represents the signals given in S ∈ (N x F) with sparse keys, minimizing the Lasso loss.\n",
    "    D ∈ (F x num_atoms).\n",
    "    X ∈ (num_atoms x N).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    S : array_like\n",
    "        Signals to be represented. S ∈ (N x F).\n",
    "    num_atoms : int\n",
    "        Number of dictionary elements.\n",
    "    delta_err : float, default=None\n",
    "        Stopping criteria for change in error. Stops if the decrease in error is less than (current error * delta_err): \n",
    "            Stops if: err(t-1) - err(t) < err(t-1) * delta_err\n",
    "        Note: calc_err must be true. If calc_err is False, max_it is used. If max_it is reached, we stop regardless.\n",
    "    \"\"\"\n",
    "    assert delta_err is None or calc_err, \"Early stopping is not possible without error calculations.\"  # delta_err implies calc_err\n",
    "        \n",
    "    np.random.seed(seed)\n",
    "    S = S.T  # S ∈ (F x N)\n",
    "    D = np.random.randn(S.shape[0], num_atoms)\n",
    "    D = D / np.linalg.norm(D, axis=0, ord=2)\n",
    "    k = 0\n",
    "    if calc_err:\n",
    "        E = np.zeros(max_it)\n",
    "    \n",
    "    while k < max_it:\n",
    "        X = lasso_solver_ADMM(D, S, max_it=max_admm)\n",
    "        D = S @ np.linalg.pinv(X)  # DX = S  ->  DXX+ = SX+  ->  D = SX+            (Y @ S') \\ (S @ S')\n",
    "        D = D / np.linalg.norm(D, axis=0, ord=2)\n",
    "        \n",
    "        if calc_err:\n",
    "            err = np.linalg.norm((D @ X) - S, ord=2, axis=None)\n",
    "            E[k] = err\n",
    "            if k > 1 and delta_err is not None and np.abs(E[k - 1] - E[k]) < E[k - 1] * delta_err:\n",
    "                if printing:\n",
    "                    print_progress(k + 1, max_it, add_newline=True)\n",
    "                    print(f\"Stopping early. Abs error diff: {np.abs(E[k - 1] - E[k]):.2e}, Threshold: {E[k - 1] * delta_err:.2e}\")\n",
    "                k = k + 1\n",
    "                return D, X, E[:k]\n",
    "            \n",
    "        k = k + 1\n",
    "        if printing:\n",
    "            print_progress(k, max_it)\n",
    "        \n",
    "    if calc_err:\n",
    "        return D, X, E\n",
    "    return D, X\n",
    "\n",
    "def lasso_solver_ADMM(A, b, max_it=100):\n",
    "    x = np.zeros((A.shape[1], b.shape[1]))\n",
    "    z = np.zeros_like(x)\n",
    "    y = np.zeros_like(x)\n",
    "    AtA = A.T @ A\n",
    "    I = np.eye(AtA.shape[0])\n",
    "    Atb = A.T @ b\n",
    "    tau_ = 0.08  # one over tau\n",
    "    lambda_tau = 0.01 / tau_  # lambda * tau\n",
    "    k = 0\n",
    "    \n",
    "    while k < max_it:\n",
    "        x = np.linalg.solve(AtA + tau_ * I, Atb + tau_ * (z - y))\n",
    "        z = soft_threshold(x + y, lambda_tau)\n",
    "        y = y + tau_ * (x - z)\n",
    "        k = k + 1\n",
    "        \n",
    "    return x\n",
    "\n",
    "def soft_threshold(x, lambda_):\n",
    "    \"\"\"\n",
    "    Implements:\n",
    "        x - lambda    if x > lambda\n",
    "        x + lambda    if x < -lambda\n",
    "        0             otherwise (x in [-lambda, lambda])\n",
    "    \"\"\"\n",
    "    return np.maximum(0, x - lambda_) - np.maximum(0, -lambda_ - x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c021efd",
   "metadata": {},
   "source": [
    "### Set the path to the beats extracted before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5b322f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = osj(\"..\", \"dataset_beats\")\n",
    "DICT_BEATS = osj(DATA_ROOT, \"5min_normal_beats.pkl\")\n",
    "DATA_BEATS = osj(DATA_ROOT, \"25min_beats.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33555229",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_beats = read_dict_beats()\n",
    "data_beats = read_data_beats()\n",
    "ensure_normalized_and_detrended(dict_beats)\n",
    "ensure_normalized_and_detrended(data_beats)\n",
    "\n",
    "patient_ids = pd.read_csv(osj(\"..\", \"files\", \"patient_ids.csv\"), header=None).to_numpy().reshape(-1)\n",
    "paced_patients = pd.read_csv(osj(\"..\", \"files\", \"paced_patients.csv\"), header=None).to_numpy().reshape(-1)\n",
    "excluded_patients = pd.read_csv(osj(\"..\", \"files\", \"excluded_patients.csv\"), header=None).to_numpy().reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea47296d",
   "metadata": {},
   "source": [
    "### Generate the dictionary for each patient and save it.\n",
    "- **Seed=patient_id is used when generating dictionaries to be reproducable.**\n",
    "- **Additionally, the dictionaries are now sorted based on the occurrence of keys of the beats creating it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54419fe3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [====================]\u001b[2k\n",
      "20/20 [====================]\u001b[2k\u001b[2k\n",
      "20/20 [====================]\u001b[2k\n",
      "20/20 [====================]\u001b[2k\n",
      "20/20 [====================]\u001b[2k\n",
      "20/20 [====================]\u001b[2k\n",
      "20/20 [====================]\u001b[2k\n",
      "20/20 [====================]\u001b[2k\n",
      "20/20 [====================]\u001b[2k\n",
      "20/20 [====================]\u001b[2k\n",
      "20/20 [====================]\u001b[2k\n",
      "20/20 [====================]\u001b[2k\n",
      "20/20 [====================]\u001b[2k\n",
      "20/20 [====================]\u001b[2k\u001b[2k\n",
      "20/20 [====================]\u001b[2k\n",
      "20/20 [====================]\u001b[2k\n",
      "20/20 [====================]\u001b[2k\n",
      "20/20 [====================]\u001b[2k\n",
      "20/20 [====================]\u001b[2k\n",
      "20/20 [====================]\u001b[2k\n",
      "20/20 [====================]\u001b[2k\n",
      "20/20 [====================]\u001b[2k\n",
      "20/20 [====================]\u001b[2k\n",
      "20/20 [====================]\u001b[2k\n",
      "20/20 [====================]\u001b[2k\n",
      "20/20 [====================]\u001b[2k\n",
      "20/20 [====================]\u001b[2k\u001b[2k\n",
      "20/20 [====================]\u001b[2k\n",
      "20/20 [====================]\u001b[2k\n",
      "20/20 [====================]\u001b[2k\n",
      "20/20 [====================]\u001b[2k\n",
      "20/20 [====================]\u001b[2k\n",
      "20/20 [====================]\u001b[2k\n",
      "20/20 [====================]\u001b[2k\n",
      "47/48 [=================== ]\u001b[2k\r"
     ]
    }
   ],
   "source": [
    "Ds = {}\n",
    "DICT_PATH = osj(\"..\", \"dictionaries\", \"dictionaries_5min_sorted\")\n",
    "save = True\n",
    "\n",
    "for i, patient_id in enumerate(patient_ids):\n",
    "    if patient_id in paced_patients or patient_id in excluded_patients:\n",
    "        continue\n",
    "        \n",
    "    dict_beat = dict_beats[patient_id][\"beats\"]\n",
    "    D, X, E = generate_dictionary(dict_beat, num_atoms=20, delta_err=None, max_it=20, max_admm=100, calc_err=True, seed=patient_id, printing=True)\n",
    "    \n",
    "    # sort D in decreasing order, based on the l1-norm of X's rows.\n",
    "    sortidx = np.argsort(np.abs(X).sum(axis=1))[::-1]\n",
    "    D = D[:, sortidx]\n",
    "    X = X[sortidx, :]\n",
    "    \n",
    "    F = spl.null_space(D.T)\n",
    "    F = spl.orth(F).T\n",
    "    \n",
    "    Ds[patient_id] = D\n",
    "    \n",
    "    if save:\n",
    "        with open(osj(DICT_PATH, f\"patient_{patient_id}_dictionary.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(D, f)\n",
    "        \n",
    "    print_progress(i + 1, len(patient_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53e552bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_dictionary(D):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(D.shape[1]):\n",
    "        plt.plot(D[:, i] + 20 - i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b11386b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_keys(X):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    sns.heatmap(X, cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81c1f4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_fit(D, X, beats):\n",
    "    plt.plot(D @ X, \"C0\", alpha=0.02)\n",
    "    plt.plot(beats, \"C1\", alpha=0.02)\n",
    "    plt.show()\n",
    "    return np.linalg.norm((D @ X - beats), ord=2, axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979d2611",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_fit(D, X, dict_beat.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb19b506",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_dictionary(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3658e3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_keys(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52087aa",
   "metadata": {},
   "source": [
    "### Domain Adaptation from one patient to another. <br> Problem: Given two patients, modify the beats of one patient to improve its beat representation on another patient's dictionary.\n",
    "### $$ \n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\hat{Q}, \\hat{C}_j &= \\underset{Q,\\,C_j}{\\arg\\min} \\, J \\\\\n",
    "J &=  \\|QX_j - D_iC_j\\|_2^2 + \\|C_j\\|_1 + \\gamma\\|X_j - QX_j\\|_2^2 \\\\\n",
    "\\dfrac{\\partial J}{\\partial Q} &= 2\\left( QX_j - D_iC_j \\right)X_j^T - 2\\gamma\\left( X_j - Q_jX_j \\right)X_j^T \\\\\n",
    "  &= Q_jX_jX_j^T - D_iC_jX_j^T - \\gamma X_jX_j^T + \\gamma Q_jX_jX_j^T = 0 \\\\\n",
    "Q &= \\left( D_iC_jX_j^T + \\gamma X_jX_j^T \\right) \\left( X_jX_j^T + \\gamma X_jX_j^T \\right)^{-1}\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "$$ <br> where $Q$ is the matrix that transforms $X_j$ to another domain so that it is better represented with $D_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ec6e7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DomainAdapter():\n",
    "    def __init__(self):\n",
    "        self.adapted = False\n",
    "    \n",
    "    def adapt(self, Di, Sj, gamma: int, max_it: int=100, max_admm: int=100, plot=False):\n",
    "        Q = np.eye(Di.shape[0])\n",
    "        Sj = Sj.T\n",
    "        \n",
    "        # Save for speedup\n",
    "        SjSjT = Sj @ Sj.T\n",
    "        gSjSjT = gamma * SjSjT\n",
    "\n",
    "        if plot:\n",
    "            plt.figure()\n",
    "        for i in range(max_it):\n",
    "            QSj = Q @ Sj\n",
    "            if plot:\n",
    "                plt.plot(QSj[:, 0], label=f\"iter={i}\")\n",
    "            QSj = QSj / np.linalg.norm(QSj, axis=0, ord=2)\n",
    "            Cj = lasso_solver_ADMM(Di, QSj, max_it=max_admm)\n",
    "            Q = (Di @ Cj @ Sj.T + gSjSjT) @ np.linalg.pinv(SjSjT + gSjSjT)\n",
    "            \n",
    "        if plot:\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "        self.Q = Q\n",
    "        self.adapted = True\n",
    "        return Q\n",
    "    \n",
    "    def adapt_gd(self, Di, Sj, gamma: int, lr: float=0.01, max_epochs: int=100, max_admm: int=100, plot=False):\n",
    "        Q = np.eye(Di.shape[0])\n",
    "        Sj = Sj.T\n",
    "\n",
    "        # Save for speedup\n",
    "        SjSjT = Sj @ Sj.T\n",
    "        gSjSjT = gamma * SjSjT\n",
    "\n",
    "        if plot:\n",
    "            plt.figure()\n",
    "        for i in range(max_epochs):\n",
    "            QSj = Q @ Sj\n",
    "            if plot and i % 10 == 0:\n",
    "                plt.plot(QSj[:, 0], label=f\"iter={i}\")\n",
    "            QSj = QSj / np.linalg.norm(QSj, axis=0, ord=2)\n",
    "            Cj = lasso_solver_ADMM(Di, QSj, max_it=max_admm)\n",
    "            \n",
    "            grad_Q = Q @ SjSjT - Di @ Cj @ Sj.T - gSjSjT + gamma * Q @ SjSjT\n",
    "            Q = Q - lr * grad_Q\n",
    "        \n",
    "        if plot:\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        \n",
    "        self.Q = Q\n",
    "        self.adapted = True\n",
    "        return Q\n",
    "    \n",
    "    def test(self, Di, Si_D, Si_T, yi, Sj_D, Sj_T, yj, Q, max_it: int=100):\n",
    "        assert self.adapted, \"Call adapt first.\"\n",
    "        \n",
    "        # Fit of i's dictionary beats.\n",
    "        Ci_D = lasso_solver_ADMM(Di, Si_D.T, max_it=max_it)\n",
    "        Ei_D = np.linalg.norm((Di @ Ci_D) - Si_D.T, ord=2, axis=0).mean()\n",
    "        \n",
    "        # Fit of i's train/test beats.\n",
    "        Ci_T = lasso_solver_ADMM(Di, Si_T.T, max_it=max_it)\n",
    "        Ei_T = np.linalg.norm((Di @ Ci_T) - Si_T.T, ord=2, axis=0)\n",
    "        Ei_T_healthy = Ei_T[yi == \"N\"].mean()\n",
    "        Ei_T_arrhyth = Ei_T[yi != \"N\"].mean()\n",
    "        \n",
    "        # Fit of j's dictionary beats on i's dictionary.\n",
    "        Cj_D = lasso_solver_ADMM(Di, Sj_D.T, max_it=max_it)\n",
    "        Ej_D = np.linalg.norm((Di @ Cj_D) - Sj_D.T, ord=2, axis=0).mean()\n",
    "        \n",
    "        # Fit of j's train/test beats on i's dictionary.\n",
    "        Cj_T = lasso_solver_ADMM(Di, Sj_T.T, max_it=max_it)\n",
    "        Ej_T = np.linalg.norm((Di @ Cj_T) - Sj_T.T, ord=2, axis=0)\n",
    "        Ej_T_healthy = Ej_T[yj == \"N\"].mean()\n",
    "        Ej_T_arrhyth = Ej_T[yj != \"N\"].mean()\n",
    "        \n",
    "        # Fit of j's dictionary beats on i's dictionary after domain adaptation.\n",
    "        QSj_D = Q @ Sj_D.T\n",
    "        QSj_D = QSj_D / np.linalg.norm(QSj_D, axis=0, ord=2)\n",
    "        \n",
    "        DA_Cj_D = lasso_solver_ADMM(Di, QSj_D, max_it=max_it)\n",
    "        DA_Ej_D = np.linalg.norm((Di @ DA_Cj_D) - QSj_D, ord=2, axis=0).mean()\n",
    "        \n",
    "        # Fit of j's train/test beats on i's dictionary after domain adaptation.\n",
    "        QSj_T = Q @ Sj_T.T\n",
    "        QSj_T = QSj_T / np.linalg.norm(QSj_T, axis=0, ord=2)\n",
    "        \n",
    "        DA_Cj_T = lasso_solver_ADMM(Di, QSj_T, max_it=max_it)\n",
    "        DA_Ej_T = np.linalg.norm((Di @ DA_Cj_T) - QSj_T, ord=2, axis=0)\n",
    "        DA_Ej_T_healthy = DA_Ej_T[yj == \"N\"].mean()\n",
    "        DA_Ej_T_arrhyth = DA_Ej_T[yj != \"N\"].mean()\n",
    "        \n",
    "        d = {\n",
    "            \"Ei_D\": Ei_D, \"Ei_T_healthy\": Ei_T_healthy, \"Ei_T_arrhyth\": Ei_T_arrhyth,\n",
    "            \"Ej_D\": Ej_D, \"Ej_T_healthy\": Ej_T_healthy, \"Ej_T_arrhyth\": Ej_T_arrhyth,\n",
    "            \"DA_Ej_D\": DA_Ej_D, \"DA_Ej_T_healthy\": DA_Ej_T_healthy, \"DA_Ej_T_arrhyth\": DA_Ej_T_arrhyth\n",
    "        }\n",
    "        \n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fbab2d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patient_adaptation_matrix(i, j, gamma, lr, max_epochs):\n",
    "    DA = DomainAdapter()\n",
    "    Q = DA.adapt_gd(Ds[i], dict_beats[j][\"beats\"], gamma=gamma, lr=lr, max_epochs=max_epochs)\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca1d7ce",
   "metadata": {},
   "source": [
    "### Generate the train, test, and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f3e2216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patient_beat_class_counts():\n",
    "    \"\"\"\n",
    "    Finds the number of healthy and arrhythmia beats for each patient.\n",
    "    \"\"\"\n",
    "    healthies = []\n",
    "    arrhythmias = []\n",
    "    for i, patient_id in enumerate(patient_ids):\n",
    "        data_beat = data_beats[patient_id][\"beats\"]\n",
    "        data_class = data_beats[patient_id][\"class\"]\n",
    "        num_healthy = np.count_nonzero(data_class == \"N\")\n",
    "        num_arrhyth = np.count_nonzero(data_class != \"N\")\n",
    "        healthies.append(num_healthy)\n",
    "        arrhythmias.append(num_arrhyth)\n",
    "    # pd.DataFrame(data=[patient_ids, healthies, arrhythmias], index=[\"patient_id\", \"num_healthy\", \"num_arrhythmia\"]).T.to_csv(\"patient_beat_class_counts.csv\", index=False)\n",
    "    return np.array(healthies), np.array(arrhythmias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f202cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patient_healthy_and_arrhythmia(patient_id, healthy_leq_arrhyth=True):\n",
    "    \"\"\"\n",
    "    Returns healthy and arrhythmia beats of patient, where number of healthy returned <= number of arrhythmia returned.\n",
    "    \"\"\"\n",
    "    data_beat = data_beats[patient_id][\"beats\"]\n",
    "    data_class = data_beats[patient_id][\"class\"]\n",
    "    idx_healthy = np.where(data_class == \"N\")[0]\n",
    "    idx_arrhyth = np.where(data_class != \"N\")[0]\n",
    "    num_healthy = len(idx_healthy)\n",
    "    num_arrhyth = len(idx_arrhyth)\n",
    "    \n",
    "    if healthy_leq_arrhyth and num_healthy > num_arrhyth:\n",
    "        num_healthy = num_arrhyth  # take only as much as arrhythmias, maybe try to take all healthies?\n",
    "    \n",
    "    healthies = data_beat[idx_healthy[:num_healthy], ...]\n",
    "    arrhythmias = data_beat[idx_arrhyth[:num_arrhyth], ...]\n",
    "    return healthies, arrhythmias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "282b9cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patient_train_data(patient_id):\n",
    "    \"\"\"\n",
    "    For patient p, prepare p's train data by getting other patients' healthy and arrhythmia beats + p's dictionary beats. \n",
    "    Healthy beats must be <= arrhythmia beats.\n",
    "    \"\"\"\n",
    "    train_X = []\n",
    "    train_y = []\n",
    "    train_ids = []\n",
    "    for i, other_id in enumerate(patient_ids):\n",
    "        if other_id == patient_id or other_id in paced_patients or other_id in excluded_patients:\n",
    "            continue\n",
    "        other_healthy, other_arrhyth = get_patient_healthy_and_arrhythmia(other_id)\n",
    "        \n",
    "        Q = get_patient_adaptation_matrix(patient_id, other_id, gamma=0.2, lr=0.002, max_epochs=25)\n",
    "        other_healthy = (Q @ other_healthy.T)\n",
    "        other_healthy = other_healthy / np.linalg.norm(other_healthy, axis=0, ord=2)\n",
    "        other_healthy = other_healthy.T\n",
    "        \n",
    "        other_arrhyth = (Q @ other_arrhyth.T)\n",
    "        other_arrhyth = other_arrhyth / np.linalg.norm(other_arrhyth, axis=0, ord=2)\n",
    "        other_arrhyth = other_arrhyth.T\n",
    "        \n",
    "        train_X.append(other_healthy)\n",
    "        train_y.append(np.zeros(len(other_healthy)))\n",
    "        train_X.append(other_arrhyth)\n",
    "        train_y.append(np.ones(len(other_arrhyth)))\n",
    "        train_ids.append(np.ones(len(other_healthy) + len(other_arrhyth)) * other_id)\n",
    "    dict_beat = dict_beats[patient_id][\"beats\"]\n",
    "    train_X.append(dict_beat)\n",
    "    train_y.append(np.zeros(len(dict_beat)))\n",
    "    train_ids.append(np.ones(len(dict_beat)) * patient_id)\n",
    "    \n",
    "    return np.concatenate(train_X, axis=0), np.concatenate(train_y, axis=0), np.concatenate(train_ids, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e826b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patient_test_data(patient_id):\n",
    "    \"\"\"\n",
    "    For patient p, prepare p's test data from p's 25 minute beats (i.e. beats that are not dictionary beats).\n",
    "    \"\"\"\n",
    "    data_beat = data_beats[patient_id][\"beats\"]\n",
    "    data_class = data_beats[patient_id][\"class\"]\n",
    "    idx_healthy = np.where(data_class == \"N\")[0]\n",
    "    idx_arrhyth = np.where(data_class != \"N\")[0]\n",
    "    \n",
    "    test_X = [data_beat[idx_healthy], data_beat[idx_arrhyth]]\n",
    "    test_y = [np.zeros(len(idx_healthy)), np.ones(len(idx_arrhyth))]\n",
    "    test_ids = np.ones(len(idx_healthy) + len(idx_arrhyth)) * patient_id\n",
    "    \n",
    "    return np.concatenate(test_X, axis=0), np.concatenate(test_y, axis=0), test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c54680f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(X, y, ids, seed=None):\n",
    "    \"\"\"\n",
    "    Shuffle X, y and ids with the same indices, and optionally set a seed.\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    shuffle_idx = np.random.permutation(len(y))\n",
    "    return X[shuffle_idx], y[shuffle_idx], ids[shuffle_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "299f4694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validation_split(train_X, train_y, train_ids, ratio):\n",
    "    \"\"\"\n",
    "    Train/Validation split by the given ratio, where ratio is size_train / size_all. Keeps the ratio of healthy and arrhythmia beats the same in train and\n",
    "    validation sets.\n",
    "    \"\"\"\n",
    "    idx_healthy = np.where(train_y == 0)[0]\n",
    "    idx_arrhyth = np.where(train_y == 1)[0]\n",
    "    \n",
    "    num_healthy = len(idx_healthy)\n",
    "    num_arrhyth = len(idx_arrhyth)\n",
    "    \n",
    "    num_train_healthy = int(num_healthy * ratio)\n",
    "    num_train_arrhyth = int(num_arrhyth * ratio)\n",
    "    \n",
    "    num_val_healthy = num_healthy - num_train_healthy\n",
    "    num_val_arrhyth = num_arrhyth - num_train_arrhyth\n",
    "    \n",
    "    val_X = np.concatenate((train_X[idx_healthy[0:num_val_healthy]], train_X[idx_arrhyth[0:num_val_arrhyth]]))\n",
    "    val_y = np.concatenate((train_y[idx_healthy[0:num_val_healthy]], train_y[idx_arrhyth[0:num_val_arrhyth]]))\n",
    "    val_ids = np.concatenate((train_ids[idx_healthy[0:num_val_healthy]], train_ids[idx_arrhyth[0:num_val_arrhyth]]))\n",
    "    \n",
    "    train_X = np.concatenate((train_X[idx_healthy[num_val_healthy:]], train_X[idx_arrhyth[num_val_arrhyth:]]))\n",
    "    train_y = np.concatenate((train_y[idx_healthy[num_val_healthy:]], train_y[idx_arrhyth[num_val_arrhyth:]]))\n",
    "    train_ids = np.concatenate((train_ids[idx_healthy[num_val_healthy:]], train_ids[idx_arrhyth[num_val_arrhyth:]])) \n",
    "    \n",
    "    return train_X, train_y, train_ids, val_X, val_y, val_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c9fb1aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_patient_datasets():\n",
    "    \"\"\"\n",
    "    Combines all of the functions above to generate datasets for each patient.\n",
    "    \"\"\"\n",
    "    for i, patient_id in enumerate(patient_ids):\n",
    "        if patient_id in paced_patients or patient_id in excluded_patients:\n",
    "            continue\n",
    "        train_X, train_y, train_ids = get_patient_train_data(patient_id)\n",
    "        train_X, train_y, train_ids = shuffle(train_X, train_y, train_ids, seed=patient_id)\n",
    "        \n",
    "        test_X, test_y, test_ids = get_patient_test_data(patient_id)\n",
    "        test_X, test_y, test_ids = shuffle(test_X, test_y, test_ids, seed=None)\n",
    "        \n",
    "        train_X, train_y, train_ids, val_X, val_y, val_ids = train_validation_split(train_X, train_y, train_ids, ratio=0.8)\n",
    "        train_X, train_y, train_ids = shuffle(train_X, train_y, train_ids, seed=None)\n",
    "        val_X, val_y, val_ids = shuffle(val_X, val_y, val_ids, seed=None)\n",
    "        \n",
    "        with open(osj(DATASET_PATH, f\"patient_{patient_id}_dataset.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(\n",
    "                {\n",
    "                    \"train_X\": train_X,\n",
    "                    \"train_y\": train_y,\n",
    "                    \"train_ids\": train_ids,\n",
    "                    \"val_X\": val_X,\n",
    "                    \"val_y\": val_y,\n",
    "                    \"val_ids\": val_ids,\n",
    "                    \"test_X\": test_X,\n",
    "                    \"test_y\": test_y,\n",
    "                    \"test_ids\": test_ids\n",
    "                },\n",
    "                f\n",
    "            )\n",
    "        print_progress(i + 1, len(patient_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b9c6871f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = osj(\"..\", \"dataset_training\", \"dataset_domain_adapted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a40f0a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/48 [=================== ]\u001b[2k\r"
     ]
    }
   ],
   "source": [
    "generate_patient_datasets()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
