{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c49ac566",
   "metadata": {},
   "source": [
    "## Calculate confusion matrices and performance metrics using pretrained weights, domain adaptation with ensemble classification, and the threshold is chosen automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7c61eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from ecg_utilities.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from ecg_utilities import *\n",
    "\n",
    "import torch.nn.functional as Func\n",
    "\n",
    "from pytorch_sklearn import NeuralNetwork\n",
    "from pytorch_sklearn.callbacks import WeightCheckpoint, Verbose, LossPlot, EarlyStopping, Callback, CallbackInfo\n",
    "from pytorch_sklearn.utils.func_utils import to_safe_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b13db535",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_ids = pd.read_csv(osj(\"..\", \"files\", \"patient_ids.csv\"), header=None).to_numpy().reshape(-1)\n",
    "valid_patients = pd.read_csv(osj(\"..\", \"files\", \"valid_patients.csv\"), header=None).to_numpy().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9a1d218",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = osj(\"..\", \"dataset_training\", \"dataset_domain_adapted\")\n",
    "TRIO_PATH = osj(\"..\", \"dataset_training\", \"dataset_beat_trios_domain_adapted\")\n",
    "DICT_PATH = osj(\"..\", \"dictionaries\", \"dictionaries_5min_sorted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08ce93ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_PATH = osj(\"..\", \"pretrained\", \"nets\")\n",
    "SAVE_PATH = osj(\"..\", \"savefolder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56b8f845",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = [-1]\n",
    "batch_sizes = [1024]\n",
    "confidences = [0, *np.linspace(0.5, 1, 51)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebc8718",
   "metadata": {},
   "source": [
    "## What is collected?\n",
    "- ### Per repeat:\n",
    "    - #### Confusion matrices per patient (34 in total).\n",
    "    - #### Cumulative confusion matrix (1 in total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "538c97ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [====================] - 233\u001b[2k\n",
      "34/34 [====================] - 233\u001b[2k\n",
      "34/34 [====================] - 233\u001b[2k\n",
      "34/34 [====================] - 233\u001b[2k\n",
      "34/34 [====================] - 233\u001b[2k\n",
      "34/34 [====================] - 233\u001b[2k\n",
      "34/34 [====================] - 233\u001b[2k\n",
      "34/34 [====================] - 233\u001b[2k\u001b[2k\n",
      "34/34 [====================] - 233\u001b[2k\u001b[2k\n",
      "34/34 [====================] - 233\u001b[2k\n",
      "Wall time: 52.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_patient_cms = []\n",
    "all_cms = []\n",
    "all_weights = []\n",
    "all_confs = []\n",
    "repeats = 10\n",
    "\n",
    "for repeat in range(repeats):\n",
    "    patient_cms = {}\n",
    "    confs = []\n",
    "    cm = torch.zeros(2, 2)\n",
    "    \n",
    "    for i, patient_id in enumerate(valid_patients):\n",
    "        dataset = load_N_channel_dataset(patient_id, DATASET_PATH, TRIO_PATH)\n",
    "        train_X, train_y, train_ids, val_X, val_y, val_ids, test_X, test_y, test_ids = dataset.values()\n",
    "        \n",
    "        # For consulting through error energy.\n",
    "        D, F = load_dictionary(patient_id, DICT_PATH)\n",
    "        D, F = torch.Tensor(D), torch.Tensor(F)\n",
    "\n",
    "        ## Consulting Exponential - Gaussian.\n",
    "        BF = BayesianFit()\n",
    "        EF = ExponentialFit()\n",
    "        GF = GaussianFit()\n",
    "\n",
    "        # Train error.\n",
    "        train_E, E_healthy, E_arrhyth = get_error_one_patient(train_X[:, 0, :].squeeze(), F, y=train_y, as_energy=True)\n",
    "        # _, E_healthy, E_arrhyth = get_error_per_patient(train_X[:, 0, :].squeeze(), ids=train_ids, DICT_PATH=DICT_PATH, y=train_y, as_energy=True)\n",
    "        \n",
    "        EF.fit(E_healthy)\n",
    "        GF.fit(E_arrhyth)\n",
    "        consult_train_y = torch.Tensor(BF.predict(train_E, EF, GF) <= 0.5).long()\n",
    "                \n",
    "        # Validation error.\n",
    "        val_E, val_E_healthy, val_E_arrhyth = get_error_one_patient(val_X[:, 0, :].squeeze(), F, y=val_y, as_energy=True)\n",
    "        \n",
    "        EF.fit(val_E_healthy)\n",
    "        GF.fit(val_E_arrhyth)\n",
    "        consult_val_y = torch.Tensor(BF.predict(val_E, EF, GF) <= 0.5).long()\n",
    "        \n",
    "        # Test Error (be careful, we check (<= 0.5) because EF => healthy => label 0)\n",
    "        test_E = get_error_one_patient(test_X[:, 0, :].squeeze(), F, as_energy=True)\n",
    "        \n",
    "        EF.fit(E_healthy)\n",
    "        GF.fit(E_arrhyth)\n",
    "        consult_test_y = torch.Tensor(BF.predict(test_E, EF, GF) <= 0.5).long()\n",
    "        ##\n",
    "\n",
    "        # Load the neural network.\n",
    "        model = get_base_model(in_channels=train_X.shape[1])\n",
    "        model = model.to(\"cuda\")\n",
    "        crit = nn.CrossEntropyLoss()\n",
    "        optim = torch.optim.AdamW(params=model.parameters())\n",
    "        \n",
    "        net = NeuralNetwork.load_class(osj(LOAD_PATH, f\"net_{repeat+1}_{patient_id}\"), model, optim, crit)\n",
    "        weight_checkpoint_val_loss = net.cbmanager.callbacks[1]  # <- this needs to change in case weight checkpoint is not the second callback.\n",
    "        \n",
    "        net.load_weights(weight_checkpoint_val_loss)\n",
    "        \n",
    "        # Validation predictions and probabilities.\n",
    "        pred_y = net.predict(val_X, batch_size=1024, use_cuda=True, fits_gpu=True, decision_func=lambda pred_y: pred_y.argmax(dim=1)).cpu()\n",
    "        prob_y = net.predict_proba(val_X).cpu()\n",
    "        softmax_prob_y = Func.softmax(prob_y, dim=1).max(dim=1).values\n",
    "        \n",
    "        # Choose consult threshold from validation set that maximizes F1.\n",
    "        maxF1 = float(\"-inf\")\n",
    "        secondMaxF1 = float(\"-inf\")\n",
    "        maxConf = -1\n",
    "        secondMaxConf = -1\n",
    "        for conf in confidences:\n",
    "            low_confidence = softmax_prob_y < conf\n",
    "            high_confidence = softmax_prob_y >= conf\n",
    "\n",
    "            final_pred_y = torch.Tensor(np.select([low_confidence, high_confidence], [consult_val_y, pred_y])).long()\n",
    "            val_cm = get_confusion_matrix(final_pred_y, val_y, pos_is_zero=False)\n",
    "            f1 = get_performance_metrics(val_cm)[\"f1\"]\n",
    "            f1 = np.nan_to_num(f1)\n",
    "            \n",
    "            if f1 >= (maxF1 - 1e-3):\n",
    "                secondMaxF1 = maxF1\n",
    "                secondMaxConf = maxConf\n",
    "                maxF1 = f1\n",
    "                maxConf = conf\n",
    "        \n",
    "        confs.append(maxConf)\n",
    "        \n",
    "        # Test predictions and probabilities.\n",
    "        pred_y = net.predict(test_X, batch_size=1024, use_cuda=True, fits_gpu=True, decision_func=lambda pred_y: pred_y.argmax(dim=1)).cpu()\n",
    "        prob_y = net.predict_proba(test_X).cpu()\n",
    "        softmax_prob_y = Func.softmax(prob_y, dim=1).max(dim=1).values\n",
    "        \n",
    "        # Use the confidence chosen above instead of iterating all confidences.\n",
    "        for conf in [maxConf]:\n",
    "            low_confidence = softmax_prob_y < conf\n",
    "            high_confidence = softmax_prob_y >= conf\n",
    "\n",
    "            final_pred_y = torch.Tensor(np.select([low_confidence, high_confidence], [consult_test_y, pred_y])).long()\n",
    "            cm_exp = get_confusion_matrix(final_pred_y, test_y, pos_is_zero=False)\n",
    "\n",
    "            patient_cms[patient_id] = cm_exp\n",
    "            cm += cm_exp\n",
    "            \n",
    "        print_progress(i + 1, len(valid_patients), opt=[f\"{patient_id}\"])\n",
    "        \n",
    "    all_patient_cms.append(patient_cms)\n",
    "    all_cms.append(cm)\n",
    "    all_confs.append(confs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e735d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    learning_rate=0.001,\n",
    "    max_epochs=max_epochs[0],\n",
    "    batch_size=batch_sizes[0],\n",
    "    optimizer=optim.__class__.__name__,\n",
    "    loss=crit.__class__.__name__,\n",
    "    early_stopping=\"true\",\n",
    "    checkpoint_on=weight_checkpoint_val_loss.tracked,\n",
    "    dataset=\"default+trio\",\n",
    "    info=\"Results replicated for GitHub, DA + Ensemble + Validation C.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d35988ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.9819819539997826,\n",
       " 'rec': 0.9370588974004772,\n",
       " 'spe': 0.9883214007230453,\n",
       " 'pre': 0.9188503595704857,\n",
       " 'npv': 0.9910929763889235,\n",
       " 'f1': 0.9278653054626396}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_performance_metrics(torch.stack(all_cms).sum(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3bad338",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    with open(osj(SAVE_PATH, \"cms.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(all_cms, f)\n",
    "        \n",
    "    with open(osj(SAVE_PATH, \"config.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(config, f)\n",
    "        \n",
    "    with open(osj(SAVE_PATH, \"patient_cms.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(all_patient_cms, f)\n",
    "        \n",
    "    with open(osj(SAVE_PATH, \"confidences.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(all_confs, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
